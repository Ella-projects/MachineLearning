{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mnn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnn\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptim\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39moptim\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "# importing\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from collections import OrderedDict\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define data directories\n",
    "data_dir = 'data/flowers102'\n",
    "\n",
    "# Define data augmentation transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.RandomResizedCrop(180),  \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1), scale=(0.8, 1.2)),\n",
    "    transforms.RandomGrayscale(p=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "validation_transforms = transforms.Compose([\n",
    "    transforms.Resize(180),\n",
    "    transforms.CenterCrop(180),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load the datasets using Flowers102\n",
    "train_dataset = datasets.Flowers102(root=data_dir, split='train', transform=train_transforms, download=True)\n",
    "validation_dataset = datasets.Flowers102(root=data_dir, split='val', transform=validation_transforms, download=True)\n",
    "test_dataset = datasets.Flowers102(root=data_dir, split='test', transform=validation_transforms, download=True)\n",
    "\n",
    "\n",
    "class_idx_mapping = {str(i): i for i in range(102)}\n",
    "train_dataset.class_to_idx = class_idx_mapping\n",
    "validation_dataset.class_to_idx = class_idx_mapping\n",
    "test_dataset.class_to_idx = class_idx_mapping\n",
    "\n",
    "# Using the image datasets and the transforms,\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=8, num_workers=4)\n",
    "valid_dataloader = DataLoader(validation_dataset, shuffle=True, batch_size=8, num_workers=4)\n",
    "test_dataloader = DataLoader(test_dataset, shuffle=True, batch_size=8, num_workers=4)\n",
    "\n",
    "# model\n",
    "class CustomCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(OrderedDict([\n",
    "            ('fc1', nn.Linear(128 * 22 * 22, 512)),  # Adjusted for 180x180 input size reduced by 3 pooling layers\n",
    "            ('relu', nn.ReLU(inplace=True)),\n",
    "            ('dropout', nn.Dropout(p=0.5)),\n",
    "            ('fc2', nn.Linear(512, 102)),\n",
    "            ('output', nn.LogSoftmax(dim=1))\n",
    "        ]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = CustomCNN()\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "def validation(model, testloader, criterion, device):\n",
    "    test_loss = 0\n",
    "    accuracy = 0\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for images, labels in testloader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            output = model(images)\n",
    "            test_loss += criterion(output, labels).item()\n",
    "            ps = torch.exp(output)\n",
    "            equality = (labels.data == ps.max(dim=1)[1])\n",
    "            accuracy += equality.type(torch.FloatTensor).mean()\n",
    "    return test_loss, accuracy\n",
    "\n",
    "def train(model, trainloader, validloader, epochs, print_every, criterion, optimizer, device='cuda'):\n",
    "    steps = 0\n",
    "    model.train()\n",
    "    model.to(device)\n",
    "    for e in range(epochs):\n",
    "        running_loss = 0\n",
    "        for images, labels in trainloader:\n",
    "            steps += 1\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if steps % print_every == 0:\n",
    "                model.eval()\n",
    "                with torch.no_grad():\n",
    "                    validation_loss, accuracy = validation(model, validloader, criterion, device)\n",
    "                print(\"Epoch: {}/{}.. \".format(e, epochs),\n",
    "                      \"Training Loss: {:.3f}.. \".format(running_loss/print_every),\n",
    "                      \"Validation Loss: {:.3f}.. \".format(validation_loss/len(validloader)),\n",
    "                      \"Validation Accuracy: {:.3f}\".format((accuracy/len(validloader))*100))\n",
    "                model.train()\n",
    "                running_loss = 0\n",
    "\n",
    "train(model=model, trainloader=train_dataloader, validloader=valid_dataloader, epochs=500, print_every=20, criterion=criterion, optimizer=optimizer, device=device)\n",
    "\n",
    "# Testing the network\n",
    "def check_accuracy_on_test(testloader, model):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "test_accuracy = check_accuracy_on_test(test_dataloader, model)\n",
    "print('Accuracy of the network on the test images: %d %%' % test_accuracy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
